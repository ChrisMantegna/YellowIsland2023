library(readr)
tax <- read_csv("data/tax.csv")
View(tax)
library(readr)
taxcorrected <- read_csv("data/taxcorrected.csv")
View(taxcorrected)
# join summer2023both with taxcorrected to run a second nmds for each site
# load summer & tax data
# Assuming your tables are named abbreviation and name
summertax <- merge(summer23both, taxcorrected, by = species_code, all.x = TRUE)
# join summer2023both with taxcorrected to run a second nmds for each site
# load summer & tax data
# Assuming your tables are named abbreviation and name
summertax <- merge(summer23both, taxcorrected, by = "species_code", all.x = TRUE)
# View the merged table
print(summertax)
counts3 <- counts2 %>%
mutate("Section" = ifelse(your_column == "1", "Yellow", "Section"))
counts3 <- counts2 %>%
mutate("Section" = ifelse("Section" == "1:8", "Yellow", "Section"))
View(counts3)
counts3 <- counts2 %>%
mutate("Site" = ifelse("Section" == "1:8", "Yellow", "Section"))
View(counts3)
counts3 <- counts2 %>%
mutate("Site" = ifelse("Yellow" == "1:8", "Yellow", "Section"))
View(counts3)
View(algae)
# Example using vegan package
permanova_result <- adonis(algae ~ Zonation, algae = Section, method = "bray")
# Example using vegan package
permanova_result <- adonis(algae ~ "Zonation", algae = "Section", method = "bray")
View(algae_counts)
View(counts1)
View(algae1)
#load packages
library(data.table)
library(dplyr)
library('ggplot2')
library("indicspecies")
library(kableExtra)
library(knitr)
library(RColorBrewer)
library(tidyr)
library(tidyverse)
library(vegan)
#load data
read.csv("algaefull.csv")
#pie charts for algae
#clean up the data first
# Convert data types and handle missing values if any
algae <- algaefull %>%
mutate(across(everything(), as.factor)) %>%
replace(is.na(.), 0)  # Replace NA values with 0 (assuming NA means absence)
#load data
algae<- read.csv("algaefull.csv")
#pie charts for algae
#clean up the data first
# Convert data types and handle missing values if any
algae <- algae %>%
mutate(across(everything(), as.factor)) %>%
replace(is.na(.), 0)  # Replace NA values with 0 (assuming NA means absence)
# Summarize data for each SECTION and ZONATION
summary_data <- data %>%
group_by(SECTION, ZONATION) %>%
summarize_all(sum) %>%
gather(key = "ALGAE_TYPE", value = "COUNT", -SECTION, -ZONATION)
View(algae)
#load packages
library(data.table)
library(dplyr)
library('ggplot2')
library("indicspecies")
library(kableExtra)
library(knitr)
library(RColorBrewer)
library(tidyr)
library(tidyverse)
library(vegan)
#load data
algae<- read.csv("algaefull.csv")
algae <- algae %>%
mutate(across(everything(), as.factor)) %>%
replace(is.na(.), 0)  # Replace NA values with 0 (assuming NA means absence)
head(algae)
summary_data <- data %>%
group_by(SECTION, ZONATION) %>%
summarize_all(sum) %>%
gather(key = "ULVA", value = "COUNT", -SECTION, -ZONATION, -ASSIGNED_NUMBER)
# Summarize data for each SECTION and ZONATION
summary_data <- data %>%
group_by(SECTION, ZONATION) %>%
summarize_all(sum) %>%
gather(key = "ULVA", value = "COUNT", -SECTION, -NUMBER, -ASSIGNED_NUMBER, -ZONATION)
# Summarize data for each SECTION and ZONATION
summary_data <- ALGAE %>%
group_by(SECTION, ZONATION) %>%
summarize_all(sum) %>%
gather(key = "ALGAE_TYPE", value = "COUNT", -SECTION, -NUMBER, -ASSIGNED_NUMBER, -ZONATION)
#load packages
library(data.table)
library(dplyr)
library('ggplot2')
library("indicspecies")
library(kableExtra)
library(knitr)
library(RColorBrewer)
library(tidyr)
library(tidyverse)
library(vegan)
#load data
algae<- read.csv("algaefull.csv")
head(algae)
result <- algae %>%
group_by(section) %>%
summarise(across(5:19, sum, na.rm = TRUE))
result <- algae %>%
group_by(SECTION) %>%
summarise(across(5:19, sum, na.rm = TRUE))
View(algae)
df <- algae[1:482, ] %>% select(-number, -assigned_number)
df <- algae[1:482, ] %>% select(-NUMBER, -ASSIGNED_NUMBER)
rockweed_section1_L <- df %>%
filter(section == 1, zonation == 'L') %>%
summarise(rockweed_sum = sum(rockweed, na.rm = TRUE))
df <- algae[1:482, ] %>% select(-NUMBER, -ASSIGNED_NUMBER)
rockweed_section1_L <- df %>%
filter(SECTION == 1, ZONATION == 'L') %>%
summarise(rockweed_sum = sum(ROCKWEED, na.rm = TRUE))
rockweed_section1_L
View(df)
#get decontam installed if you haven't
install.packages(devtools)
library(devtools)
devtools::install_github("benjjneb/decontam")
#get decontam installed if you haven't
install.packages(devtools)
library(devtools)
library(decontam)
devtools::install_github("benjjneb/decontam")
<<<<<<< HEAD
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("decontam")
getwd()
library(dbplyr)
library(ggplot2)
tax_table18S <- read.csv("/home/shared/8TB_HDD_02/cnmntgna/GitHub/YellowIsland2023/data/Anacapa_Results/18S_taxonomy_tables/18S_ASV_taxonomy_detailed.txt", header= TRUE)
View(tax_table18S)
library(dbplyr)
library(ggplot2)
tax_table18S <- read.csv("/home/shared/8TB_HDD_02/cnmntgna/GitHub/YellowIsland2023/data/Anacapa_Results/18S_taxonomy_tables/Summary_by_percent_confidence/90/18S_ASV_sum_by_taxonomy_90.txt", header= TRUE)
View(tax_table18S)
head(tax_table18S)
summary(tax_table18S)
# Example: Summarize counts for each taxon
summarized_table <- tax_table18S %>%
group_by(Taxon) %>%
summarise(total_counts = sum(Counts))
# Example: Summarize counts for each taxon
summarized_18S <- tax_table18S %>%
group_by(Taxon) %>%
summarize(total_counts = sum(Counts))
library(dplyr)
# Example: Summarize counts for each taxon
summarized_18S <- tax_table18S %>%
group_by(Taxon) %>%
summarize(total_counts = sum(Counts))
View(tax_table18S)
tax_table18S <- read.csv("/home/shared/8TB_HDD_02/cnmntgna/GitHub/YellowIsland2023/data/Anacapa_Results/18S_taxonomy_tables/Summary_by_percent_confidence/90/18S_ASV_sum_by_taxonomy_90.txt", header= TRUE, sep = "\t")
head(tax_table18S)
summary(tax_table18S)
library(phyloseq)
library(ranacapa)
library(devtools)
library(vegan)
install.packages(phyloseq)
install.packages("phyloseq")
library(phyloseq)
source('http://bioconductor.org/biocLite.R')
install.packages("ranacapa")
# Extract the rownames of the matrix above- this has the full taxonomic path.
# Split the taxonomic path on semicolons, and turn the resulting matrix into
# a phyloseq tax_table object
taxon_names <- reshape2::colsplit(rownames(tax_table18S), ";",
names = c("Domain","Phylum","Class","Order","Family","Genus","Species")) %>%
as.matrix
rownames(taxon_names) <- rownames(tax_table18S)
tax_physeq <- phyloseq::tax_table(taxon_names)
source("https://raw.githubusercontent.com/joey711/phyloseq/master/inst/scripts/installer.R",
local = TRUE)
library(phyloseq)
View(install_phyloseq)
devtools::install_github("joey711/phyloseq")
View(install_phyloseq)
View(taxon_names)
install_github("joey711/phyloseq")
# Convert the matrix into a phyloseq otu_table object, with taxa as the rows
ana_taxon_table_physeq <- phyloseq::otu_table(tax_table18S, taxa_are_rows = TRUE)
install.packages(""phyloseq"")
install.packages(""phyloseq"")
install.packages("phyloseqGraphTest")
install.packages("vctrs")
install.packages("vctrs")
=======
#read in files
18S_30<-read.csv("~/Documents/YellowIsland2023/data/Tronko_Results/Yellow_Sep5_q35_18S_Max5.txt", header=TRUE, sep="\t")
devtools::install_github("joey711/phyloseq")
>>>>>>> b667d266c990b98d3d94ac7a1ecb6c62064c89a9
knitr::opts_chunk$set(echo = TRUE)
library(phyloseq)
library("phyloseq")
BiocManager::install("phyloseq")
library("phyloseq")
library("dada2")
BiocManager::install("dada2", version = "3.11")
BiocManager::install(version = "3.18")
knitr::opts_chunk$set(echo = TRUE)
BiocManager::install("dada2", version = "3.11")
install.packages("BiocManager")
BiocManager::install(version = "3.18")
install.packages("BiocManager")
BiocManager::install("dada2", version = "3.11")
library(BiocManager)
knitr::opts_chunk$set(echo = TRUE)
BiocManager::install("dada2", version = "3.11")
BiocManager::version()
BiocManager::install(version = "3.19")
BiocManager::install(version = "3.18")
options(repos = BiocManager::repositories())
getOption("repos")
options(repos = c(
CRAN = "https://cran.rstudio.com/",
BioCsoft = "https://bioconductor.org/packages/3.18/bioc",
BioCann = "https://bioconductor.org/packages/3.18/data/annotation",
BioCexp = "https://bioconductor.org/packages/3.18/data/experiment",
BioCworkflows = "https://bioconductor.org/packages/3.18/workflows"
))
BiocManager::version()
BiocManager::install("dada2", version = "3.11")
library("devtools")
devtools::install_github("benjjneb/dada2", ref="v1.16") # change the ref argument to get other versions
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("dada2", version = "3.9")
knitr::opts_chunk$set(echo = TRUE)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("dada2", version = "3.9")
install.packages("~/github/dada2",
repos = NULL,
type = "source",
dependencies = c("Depends", "Suggests","Imports"))
## try http:// if https:// URLs are not supported
if (!requireNamespace("BiocManager", quietly=TRUE))
install.packages("BiocManager")
BiocManager::install("dada2")
packageVersion("dada2")
update("dada2")
library("phyloseq")
library("dada2")
help(package="dada2")
BiocManager::install("dada2", version= "3.11")
BiocManager::install("dada2", version= "3.18")
packageVersion("dada2")
library("phyloseq")
library("dada2")
getwd()
getwd()
path <- "/Users/cmantegna/Desktop/yisequences"
fnFs <- sort(list.files(path, pattern = "_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = "_R2.fastq", full.names = TRUE))
getwd()
path <- "/Users/cmantegna/Desktop/yisequences"
fnFs <- sort(list.files(path, pattern = "_R1_001.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = "_R2.fastq.gz", full.names = TRUE))
getwd()
path <- "/Users/cmantegna/Desktop/yisequences"
fnFs <- sort(list.files(path, pattern = "Yell_July18_Site1s_S112_R1_001.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = "Yell_July18_Site1s_S112_R2.fastq.gz", full.names = TRUE))
path <- "/Users/cmantegna/Desktop/yisequences"
fnFs <- sort(list.files(path, pattern = "_R1_001.fastq.gz", full.names = TRUE))
path <- "/Users/cmantegna/Desktop/yisequences/"
fnFs <- sort(list.files(path, pattern = "_R1_001.fastq.gz", full.names = TRUE))
path <- "/Users/cmantegna/Desktop/ysequences"
fnFs <- sort(list.files(path, pattern = "_R1_001.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = "_R2_002.fastq.gz", full.names = TRUE))
getwd()
path <- "/Users/cmantegna/Desktop/ysequences"
fnFs <- sort(list.files(path, pattern = "_R1_001.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = "_R2_002.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = "_R2_001.fastq.gz", full.names = TRUE))
filtFs <- file.path(path, "filtered", basename(fnFs))
filtRs <- file.path(path, "filtered", basename(fnRs))
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, multithread=TRUE)
# get sample names for each by removing the ending
sampleNamesFs <- gsub("_R1_001.fastq.gz", "", basename(fnFs))
sampleNamesRs <- gsub("_R2_001.fastq.gz", "", basename(fnRs))
# find the missing one
missingReverse <- setdiff(sampleNamesFs, sampleNamesRs)
# result
print(missingReverse)
getwd()
path <- "/Users/cmantegna/Desktop/ysequences"
fnFs <- sort(list.files(path, pattern = "_R1_001.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = "_R2_001.fastq.gz", full.names = TRUE))
knitr::opts_chunk$set(echo = TRUE)
library("phyloseq")
library("dada2")
getwd()
path <- "/Users/cmantegna/Desktop/ysequences"
fnFs <- sort(list.files(path, pattern = "_R1_001.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = "_R2_001.fastq.gz", full.names = TRUE))
filtFs <- file.path(path, "filtered", basename(fnFs))
filtRs <- file.path(path, "filtered", basename(fnRs))
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, multithread=TRUE)
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
maxN=0, maxEE=c(3,5), truncQ=2, rm.phix=TRUE,
compress=TRUE, multithread=TRUE, verbose= TRUE)
View(out)
errF <- learnErrors(filtFs, multithread=TRUE)
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs,
maxN=0, maxEE=c(3,5), truncQ=2, rm.phix=TRUE,
compress=TRUE, multithread=TRUE, verbose= TRUE)
View(out)
errF <- learnErrors(filtFs, multithread=TRUE)
print(out)
nonEmptySamples <- out[,2] > 0
nonEmptySamples <- out[,2] > 0
fnFs_filtered <- filtFs[nonEmptySamples]
fnRs_filtered <- filtRs[nonEmptySamples]
errF <- learnErrors(filtFs_filtered, multithread=TRUE)
errF <- learnErrors(fnFs_filtered, multithread=TRUE)
errR <- learnErrors(fnRs_filtered, multithread=TRUE)
plotErrors(errF, nominalQ=TRUE)
derepFs <- derepFastq(fnFs_filtered)
derepRs <- derepFastq(fnRs_filtered)
derepRs <- derepFastq(fnRs_filtered)
gc()
plotErrors(errF, nominalQ=TRUE)
# 5 sequence pairs that returned 0: 1aa - 130, 1x - 119, 5d - 90, 5dd - 135, 5gg - 138
# pairs well below other sequences: 5J - 107 (70, 59), 5w - 128 (13, 13)
print(out)
# write to table
write.csv(out,"/Users/cmantegna/Documents/YellowIsland2023/filterOutput.csv", row.names = FALSE)
system("vm_stat")
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
write.csv(dadaFs,"/Users/cmantegna/Documents/YellowIsland2023/inferredFasv.csv", row.names = FALSE)
write.csv(dadaFs,"/Users/cmantegna/Documents/YellowIsland2023/inferredFasv.csv")
derepRs <- derepFastq(fnRs_filtered)
derepRs <- vector("list", length(fnRs_filtered))
for (i in seq_along(fnRs_filtered)) {
derepRs[[i]] <- derepFastq(fnRs_filtered[[i]])
}
saveRDS(dadaFs, "dadaFs.rds")
saveRDS(derepFs, "derepFs.rds")
saveRDS(errF, "errF.rds")
saveRDS(filtFs, "dadaFs.rds")
saveRDS(fnFs, "dadaFs.rds")
saveRDS(fnFs_filtered, "dadaFs.rds")
saveRDS(dadaFs, "dadaFs.rds")
saveRDS(derepFs, "derepFs.rds")
saveRDS(errF, "errF.rds")
saveRDS(filtFs, "filtFs.rds")
saveRDS(fnFs, "fnFs.rds")
saveRDS(fnFs_filtered, "fnFs_filtered.rds")
rm(dadaFs)
rm(derepFs)
rm(errF)
rm(filtFs)
rm(fnFs)
rm(fnFs_filtered)
gc()
gc()
knitr::opts_chunk$set(echo = TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
derepRs <- derepFastq(fnRs_filtered)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
dadaFs <- readRDS("dadaFs.rds")
derepFs<- readRDS("derepFs.rds")
# save- reverse
saveRDS(dadaRs, "dadaRs.rds")
saveRDS(derepRs, "derepRs.rds")
saveRDS(errR, "errR.rds")
saveRDS(filtRs, "filtRs.rds")
saveRDS(fnRs, "fnRs.rds")
saveRDS(fnRs_filtered, "fnRs_filtered.rds")
derepFs<- readRDS("derepFs.rds")
gc()
library(knitr)
#install.packages("rmdformats")
#library(rmdformats)
library("kableExtra")
## Global options
# The following line is necessary to make sure that
# everything is not reevaluated each time the file is knit
# Note : in the case of this report it is necessary to leave cache= FALSE
options(max.print="75")
knitr::opts_chunk$set(fig.width=8,
fig.height=6,
eval=TRUE,
cache=TRUE,
echo=TRUE,
prompt=FALSE,
tidy=TRUE,
comment=NA,
message=FALSE,
warning=FALSE)
opts_knit$set(width=85)
library("phyloseq")
library("ggplot2")      # graphics
library("readxl")       # necessary to import the data from Excel file
library("dplyr")        # filter and reformat data frames
library("tibble")       # Needed for converting column to row names
library(reader)
# metadata
meta<- read.csv("/Users/cmantegna/Documents/YellowIsland2023/data/yimetadata.csv")
# asv from dada2 for otu creation
asv<- read_csv("/Users/cmantegna/Documents/YellowIsland2023/data/ExportedASVtable.csv", row.names = 1)
library(reader)
# asv from dada2 for otu creation
asv<- read_csv("/Users/cmantegna/Documents/YellowIsland2023/data/ExportedASVtable.csv", row.names = 1)
library(readr)
library(knitr)
#install.packages("rmdformats")
#library(rmdformats)
library("kableExtra")
## Global options
# The following line is necessary to make sure that
# everything is not reevaluated each time the file is knit
# Note : in the case of this report it is necessary to leave cache= FALSE
options(max.print="75")
knitr::opts_chunk$set(fig.width=8,
fig.height=6,
eval=TRUE,
cache=TRUE,
echo=TRUE,
prompt=FALSE,
tidy=TRUE,
comment=NA,
message=FALSE,
warning=FALSE)
opts_knit$set(width=85)
library("phyloseq")
library("ggplot2")      # graphics
library("readxl")       # necessary to import the data from Excel file
library("dplyr")        # filter and reformat data frames
library("tibble")       # Needed for converting column to row names
library(readr)
# metadata
meta<- read.csv("/Users/cmantegna/Documents/YellowIsland2023/data/yimetadata.csv")
# asv from dada2 for otu creation
asv<- read_csv("/Users/cmantegna/Documents/YellowIsland2023/data/ExportedASVtable.csv", row.names = 1)
# asv from dada2 for otu creation
asv<- read_csv("/Users/cmantegna/Documents/YellowIsland2023/data/ExportedASVtable.csv")
# taxonomy table from tronko
tax18<- read_csv("/Users/cmantegna/Documents/YellowIsland2023/data/Tronko_Results/Yellow_Sep5_q35_18S_Max5.txt", header=TRUE, sep="\t")
# taxonomy table from tronko
tax18 <- read_tsv("/Users/cmantegna/Documents/YellowIsland2023/data/Tronko_Results/Yellow_Sep5_q35_18S_Max5.txt")
otu <- otu_table(as.matrix(asv), taxa_are_rows = TRUE)
str(asv)
asv_numeric <- asv
asv_numeric[,-1] <- lapply(asv_numeric[,-1], as.numeric)
otu <- otu_table(as.matrix(asv_numeric), taxa_are_rows = TRUE)
asv_numeric <- apply(asv, 2, as.numeric)
otu <- otu_table(as.matrix(asv_numeric), taxa_are_rows = TRUE)
asv_numeric <- asv
asv_numeric[,-1] <- lapply(asv_numeric[,-1], function(x) as.numeric(gsub("[^0-9.]", "", x)))
# Check for any non-numeric values
any(is.na(asv_numeric))
otu <- otu_table(as.matrix(asv_numeric), taxa_are_rows = TRUE)
# check asv
str(asv)
# make numeric
asv_numeric <- apply(asv, 2, as.numeric)
# create otu
otu <- otu_table(as.matrix(asv_numeric), taxa_are_rows = TRUE)
any(is.na(asv_numeric))
physeq <- phyloseq(otu, meta, tax18)
sample_names(physeq)
asv_numeric <- asv
asv_numeric[,-1] <- lapply(asv_numeric[,-1], function(x) as.numeric(gsub("[^0-9.]", "", x)))
# Check for any non-numeric values
any(is.na(asv_numeric))
# create otu
otu <- otu_table(as.matrix(asv_numeric), taxa_are_rows = TRUE)
library(knitr)
#install.packages("rmdformats")
#library(rmdformats)
library("kableExtra")
options(max.print="75")
knitr::opts_chunk$set(fig.width=8,
fig.height=6,
eval=TRUE,
cache=TRUE,
echo=TRUE,
prompt=FALSE,
tidy=TRUE,
comment=NA,
message=FALSE,
warning=FALSE)
opts_knit$set(width=85)
library("dada2")
library("phyloseq")
library("ggplot2")      # graphics
library("readxl")       # necessary to import the data from Excel file
library("dplyr")        # filter and reformat data frames
library("tibble")       # Needed for converting co
